{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# WELCOME TO PYTHON COURSE (23.09)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUDENTS QUESTION ANSWERED\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AUTOMATIC SEABORN PLOTTING FUNCTION \n",
    "# Function that handles plot generation\n",
    "def generate_plot(plot_type, x=None, y=None, hue=None, data=None, title='', filename='', **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    match plot_type:\n",
    "        case 'boxplot':\n",
    "            sns.boxplot(x=x, y=y, data=data, ax=ax, **kwargs)\n",
    "        case 'scatterplot':\n",
    "            sns.scatterplot(x=x, y=y, hue=hue, data=data, ax=ax, **kwargs)\n",
    "        case 'regplot':\n",
    "            sns.regplot(x=x, y=y, data=data, ax=ax, **kwargs)\n",
    "        case _:\n",
    "            print(f\"Plot type '{plot_type}' is not recognized.\")\n",
    "            return\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    if x and y:\n",
    "        ax.set_xlabel(x)\n",
    "        ax.set_ylabel(y)\n",
    "    \n",
    "    # Rotate x-axis labels if needed\n",
    "    if plot_type == 'boxplot':\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    # Save and close the plot\n",
    "    save_plot(fig, filename)\n",
    "\n",
    "\n",
    "# AUTOMATIC MATPLOTLIB FUNCTION\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper function to save the plot\n",
    "def save_plot(fig, filename):\n",
    "    fig.savefig(filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function that handles Matplotlib plot generation\n",
    "def generate_matplotlib_plot(plot_type, x=None, y=None, data=None, title='', xlabel='', ylabel='', filename='', **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    match plot_type:\n",
    "        case 'line':\n",
    "            ax.plot(data[x], data[y], **kwargs)\n",
    "        case 'scatter':\n",
    "            ax.scatter(data[x], data[y], **kwargs)\n",
    "        case 'bar':\n",
    "            ax.bar(data[x], data[y], **kwargs)\n",
    "        case 'hist':\n",
    "            ax.hist(data[x], **kwargs)\n",
    "        case _:\n",
    "            print(f\"Plot type '{plot_type}' is not recognized.\")\n",
    "            return\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel if xlabel else x)\n",
    "    ax.set_ylabel(ylabel if ylabel else y)\n",
    "\n",
    "    # Rotate x-axis labels if needed\n",
    "    if plot_type == 'bar':\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    # Save and close the plot\n",
    "    save_plot(fig, filename)\n",
    "\n",
    "# Salary Analysis Function using Matplotlib\n",
    "def salary_analysis_matplotlib(merged_df):\n",
    "    # a. Salary distribution across departments (using bar plot as an example)\n",
    "    generate_matplotlib_plot(\n",
    "        plot_type='bar',\n",
    "        x='Department',\n",
    "        y='Salary',\n",
    "        data=merged_df,\n",
    "        title='Salary Distribution Across Departments (Bar Plot)',\n",
    "        xlabel='Department',\n",
    "        ylabel='Salary',\n",
    "        filename='1a_salary_distribution_matplotlib.png'\n",
    "    )\n",
    "\n",
    "    # b. Salary vs. years of experience (using scatter plot)\n",
    "    generate_matplotlib_plot(\n",
    "        plot_type='scatter',\n",
    "        x='YearsOfExperience',\n",
    "        y='Salary',\n",
    "        data=merged_df,\n",
    "        title='Salary vs Years of Experience (Scatter Plot)',\n",
    "        xlabel='Years of Experience',\n",
    "        ylabel='Salary',\n",
    "        filename='1b_salary_vs_experience_matplotlib.png'\n",
    "    )\n",
    "\n",
    "    # c. Correlation between performance rating and salary (using line plot as an example)\n",
    "    correlation = merged_df['Salary'].corr(merged_df['PerformanceRating'])\n",
    "    generate_matplotlib_plot(\n",
    "        plot_type='line',\n",
    "        x='PerformanceRating',\n",
    "        y='Salary',\n",
    "        data=merged_df,\n",
    "        title=f'Salary and Performance Rating Correlation: {correlation:.2f} (Line Plot)',\n",
    "        xlabel='Performance Rating',\n",
    "        ylabel='Salary',\n",
    "        filename='1c_salary_performance_correlation_matplotlib.png'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "---\n",
    "\n",
    "### MATPLOTLIB SNS HOVER EFFECTS\n",
    "\n",
    "To add hover functionality with detailed data to your visualizations, you can use **Plotly**, an interactive plotting library, instead of `Matplotlib` and `Seaborn`, which do not natively support hover interactivity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Results Seaborn (-> 10 Uhr)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All visualizations have been saved as PNG files in the current directory.\n"
     ]
    }
   ],
   "source": [
    "# Results Seaborn task\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('startup_data.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df['StartDate'] = pd.to_datetime(df['StartDate'])\n",
    "\n",
    "# Set the style for all plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Task 1: Bar Plot - Average Salary by Department\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Department', y='Salary', data=df)\n",
    "plt.title('Average Salary by Department')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task1_bar_plot_salary_by_department.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 2: Scatter Plot - Salary vs Performance Rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PerformanceRating', y='Salary', data=df)\n",
    "plt.title('Salary vs Performance Rating')\n",
    "plt.tight_layout()\n",
    "plt.savefig('task2_scatter_plot_salary_vs_performance.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 3: Box Plot - Salary Distribution by Department\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Department', y='Salary', data=df)\n",
    "plt.title('Salary Distribution by Department')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task3_box_plot_salary_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 4: Count Plot - Number of Employees by Department\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Department', data=df)\n",
    "plt.title('Number of Employees by Department')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task4_count_plot_employees_by_department.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 5: Line Plot - Salary Over Time (Start Dates)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='StartDate', y='Salary', data=df)\n",
    "plt.title('Salary Over Time (Start Dates)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task5_line_plot_salary_over_time.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 6: Heatmap - Correlation Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('task6_heatmap_correlation_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 7: Violin Plot - Salary Distribution by Department\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='Department', y='Salary', data=df)\n",
    "plt.title('Salary Distribution by Department')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task7_violin_plot_salary_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 8: Pair Plot - Relationships Between Numerical Features\n",
    "numerical_features = ['Salary', 'PerformanceRating', 'YearsOfExperience', 'Age']\n",
    "sns.pairplot(df[numerical_features])\n",
    "plt.tight_layout()\n",
    "plt.savefig('task8_pair_plot_numerical_features.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 9: Histogram - Salary Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Salary'], kde=True)\n",
    "plt.title('Salary Distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('task9_histogram_salary_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 10: FacetGrid - Performance Rating by Project\n",
    "g = sns.FacetGrid(df, col=\"Project\", col_wrap=3, height=4, aspect=1.5)\n",
    "g.map(sns.scatterplot, \"PerformanceRating\", \"Salary\")\n",
    "g.add_legend()\n",
    "g.fig.suptitle('Performance Rating vs Salary by Project', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task10_facetgrid_performance_by_project.png')\n",
    "plt.close()\n",
    "\n",
    "# Task 11: Strip Plot - Performance Rating by Role\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.stripplot(x='Role', y='PerformanceRating', data=df, jitter=True)\n",
    "plt.title('Performance Rating by Role')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task11_strip_plot_performance_by_role.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"All visualizations have been saved as PNG files in the current directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# TEST MATPLOTLIB (10.15 -> 11 Uhr) \n",
    "\n",
    "---\n",
    "For this test create an testResult_topic_yourName.py and for each answer write an example code that is executable and correct!\n",
    "#### **Question 1:**\n",
    "What is the primary function used to create a basic plot in Matplotlib?\n",
    "- a) `plt.plot()`\n",
    "- b) `plt.create()`\n",
    "- c) `plt.draw()`\n",
    "- d) `plt.chart()`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 2:**\n",
    "Which module do you import to use Matplotlib in Python?\n",
    "- a) `import matplotlib as plt`\n",
    "- b) `import matplotlib.pyplot as plt`\n",
    "- c) `import matplotlib.graph as plt`\n",
    "- d) `import matplotlib.data as plt`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 3:**\n",
    "How can you set the title of a plot using Matplotlib?\n",
    "- a) `plt.title('My Plot')`\n",
    "- b) `plt.set_title('My Plot')`\n",
    "- c) `plt.plot_title('My Plot')`\n",
    "- d) `plt.label('My Plot')`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 4:**\n",
    "What method is used to add a grid to the plot?\n",
    "- a) `plt.show_grid()`\n",
    "- b) `plt.grid()`\n",
    "- c) `plt.add_grid()`\n",
    "- d) `plt.draw_grid()`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 5:**\n",
    "Which of the following is the correct way to create a scatter plot?\n",
    "- a) `plt.scatter(x, y)`\n",
    "- b) `plt.plot_scatter(x, y)`\n",
    "- c) `plt.scatter_plot(x, y)`\n",
    "- d) `plt.plot(x, y, 'o')`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 6:**\n",
    "How do you save a Matplotlib figure to a file (e.g., PNG)?\n",
    "- a) `plt.savefig(\"filename.png\")`\n",
    "- b) `plt.savefig('filename.png')`\n",
    "- c) `plt.writefig('filename.png')`\n",
    "- d) `plt.save('filename.png')`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 7:**\n",
    "What method is used to add labels to the x and y axes of a plot?\n",
    "- a) `plt.label(x='x-axis', y='y-axis')`\n",
    "- b) `plt.xlabel('x-axis')` and `plt.ylabel('y-axis')`\n",
    "- c) `plt.set_xlabel('x-axis')` and `plt.set_ylabel('y-axis')`\n",
    "- d) `plt.axis_labels('x-axis', 'y-axis')`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 8:**\n",
    "How can you create a subplot layout with 2 rows and 3 columns?\n",
    "- a) `plt.subplots(2, 3)`\n",
    "- b) `plt.subplot(2, 3)`\n",
    "- c) `plt.subplot_grid(2, 3)`\n",
    "- d) `plt.grid(2, 3)`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 9:**\n",
    "To plot a histogram, which function is used?\n",
    "- a) `plt.hist()`\n",
    "- b) `plt.bar()`\n",
    "- c) `plt.plot()`\n",
    "- d) `plt.scatter()`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 10:**\n",
    "How do you set the x-axis and y-axis limits of a plot?\n",
    "- a) `plt.set_xlim(left, right)` and `plt.set_ylim(bottom, top)`\n",
    "- b) `plt.xlim(left, right)` and `plt.ylim(bottom, top)`\n",
    "- c) `plt.axis_limits(left, right, bottom, top)`\n",
    "- d) `plt.axis_range(left, right, bottom, top)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# LIBRARIES LEARNED (-> 11.30)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Pandas**\n",
    "Pandas is a powerful Python library primarily used for data manipulation and analysis. It provides flexible data structures, such as DataFrames and Series, which allow for efficient handling of structured data.\n",
    "\n",
    "**Key Features:**\n",
    "- **Data Structures**: DataFrames (2D labeled data) and Series (1D labeled data) facilitate easy data manipulation.\n",
    "- **Data Cleaning**: Functions for handling missing data, duplicates, and data type conversions.\n",
    "- **Data Transformation**: Ability to filter, sort, and aggregate data, as well as perform operations like merging and joining datasets.\n",
    "- **Time Series Analysis**: Built-in support for time series data, making it easy to manipulate dates and times.\n",
    "- **Group By Functionality**: Allows for grouping data and applying aggregate functions, providing insights into specific categories.\n",
    "\n",
    "**Common Use Cases:**\n",
    "- Data cleaning and preparation.\n",
    "- Exploratory data analysis.\n",
    "- Time series analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Matplotlib**\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. It is the foundational library for data visualization in Python.\n",
    "\n",
    "**Key Features:**\n",
    "- **Versatile Plotting**: Supports a wide range of plots including line charts, bar charts, histograms, scatter plots, and more.\n",
    "- **Customization**: Highly customizable, allowing detailed control over plot aesthetics (titles, labels, colors, etc.).\n",
    "- **Subplots**: Ability to create multiple plots in a single figure for comparative analysis.\n",
    "- **Integration**: Works seamlessly with NumPy and Pandas for visualizing data.\n",
    "\n",
    "**Common Use Cases:**\n",
    "- Creating publication-quality figures.\n",
    "- Simple exploratory visualizations.\n",
    "- Custom visualizations for data presentations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Seaborn**\n",
    "Seaborn is a statistical data visualization library built on top of Matplotlib. It simplifies the process of creating complex visualizations with a high-level interface.\n",
    "\n",
    "**Key Features:**\n",
    "- **Statistical Plots**: Built-in functions for creating advanced statistical plots such as heatmaps, pair plots, and violin plots.\n",
    "- **Theme Management**: Offers aesthetically pleasing default themes and color palettes to enhance visual appeal.\n",
    "- **Integration with Pandas**: Works directly with Pandas DataFrames, making it easy to visualize data without extensive preprocessing.\n",
    "- **Data Relationships**: Facilitates the exploration of relationships between variables through visualizations.\n",
    "\n",
    "**Common Use Cases:**\n",
    "- Visualizing complex datasets in a straightforward manner.\n",
    "- Creating informative statistical graphics with minimal code.\n",
    "- Exploratory data analysis to understand data distributions and relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned Skills\n",
    "- **Data Cleaning:** Identifying and handling missing values, outliers, and inconsistencies in the data to ensure accuracy and reliability.\n",
    "- **Data Transformation:** Converting data from one format to another, changing data types, and scaling numerical values to bring them into a range.\n",
    "- **Filtering and Sub-setting:** Selecting specific rows or columns based on certain conditions to focus on relevant data for analysis.\n",
    "- **Data Aggregation:** Combining data into groups and calculating summary statistics (e.g., mean, sum, count) for each group.\n",
    "- **Data Joining and Merging:** Combining data from multiple sources based on common attributes to construct a unified dataset.\n",
    "- **Pivoting and Reshaping:** Reorganizing data to change its structure, such as moving rows to columns or columns to rows (or “pivoting”) to see different summaries of the source data.\n",
    "- **Data Imputation:** Fill in missing values using various techniques to maintain the integrity of the dataset.\n",
    "\n",
    "### Missing\n",
    "- **Data Normalization:** Scaling numerical data to a standard range, often between 0 and 1, to prevent the dominance of certain features.\n",
    "- **Data Encoding:** Converting categorical variables into numerical representations for analysis.\n",
    "- **Feature Engineering:** Creating new features or variables from existing data that may improve the performance of machine learning models.\n",
    "\n",
    "\n",
    "### Data Analyst Libraries\n",
    "\n",
    "1. **Pandas**:  \n",
    "    Pandas is a fundamental data manipulation library in Python. It provides data structures like DataFrame and Series, enabling the smooth handling of structured data. Pandas offers a set of tools to facilitate data cleaning, filtering, merging, grouping, and aggregation, making it highly versatile for working with structured/tabular data.\n",
    "\n",
    "2. **NumPy**:  \n",
    "    While NumPy is primarily known for its numerical computing capabilities, it also plays a significant role in data manipulation. It provides support for arrays and matrices, enabling efficient manipulation of large datasets. NumPy serves as the foundation for many scientific computing libraries in Python, offering speed and performance for numerical operations.\n",
    "\n",
    "3. **SciPy**:  \n",
    "    SciPy builds on NumPy and provides additional scientific computing functionalities, including statistical functions, optimization, integration, interpolation, and more. It is designed for advanced mathematical functions and data science tasks that go beyond basic array operations.\n",
    "\n",
    "4. **Dask**:  \n",
    "    Dask is a parallel computing library that extends the capabilities of Pandas and NumPy. It allows you to work with larger-than-memory datasets by performing operations in parallel and leveraging distributed computing resources. Dask is commonly used for scaling up data science workflows in environments with large data and computational requirements.\n",
    "\n",
    "5. **Matplotlib**:  \n",
    "    Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. It is often used for low-level data visualization tasks and provides a wide range of plotting tools, from basic line and scatter plots to more complex visualizations. Matplotlib is highly customizable, making it ideal for detailed control over plot aesthetics.\n",
    "\n",
    "6. **Seaborn**:  \n",
    "    Seaborn is a statistical data visualization library built on top of Matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics. Seaborn simplifies the process of visualizing complex datasets, allowing for easy creation of heatmaps, pair plots, violin plots, and more. It integrates well with Pandas for seamless plotting of DataFrame objects.\n",
    "\n",
    "7. **Plotly**:  \n",
    "    Plotly is a library for creating interactive, web-based visualizations. It supports a wide variety of plots, including 3D plots, maps, and more complex dashboards. Plotly is highly interactive and allows users to create and share dynamic, web-friendly plots with minimal effort. It is especially useful for creating dashboards or interactive reports.\n",
    "\n",
    "8. **Bokeh**:  \n",
    "    Bokeh is another library focused on interactive visualizations, particularly for web browsers. Bokeh provides tools for creating elegant and versatile visualizations, supporting both interactive charts and real-time streaming data.\n",
    "\n",
    "9. **Altair**:  \n",
    "    Altair is a declarative statistical visualization library, providing an easy and concise syntax for creating a wide range of plots. It is built on top of the Vega and Vega-Lite visualization grammars and is particularly suited for creating high-level, interactive plots with minimal code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "In the realm of data analysis, effective data manipulation is crucial for extracting valuable insights from raw datasets. This document outlines key concepts and techniques in data preparation, which include data cleaning, transformation, aggregation, and visualization. By utilizing libraries such as Pandas, NumPy, and Seaborn, analysts can ensure that their datasets are accurate, reliable, and well-structured for analysis. \n",
    "\n",
    "The following sections detail various data manipulation tasks, including handling missing values, encoding categorical variables, and visualizing data trends. Understanding these processes enables analysts to prepare data effectively, making it ready for analysis and decision-making. The handout that follows provides a deeper dive into each concept, offering specific methodologies and practical applications to enhance your data manipulation skills.\n",
    "\n",
    "#### 1. Data Cleaning\n",
    "- **Definition**: Identifying and handling missing values, outliers, and inconsistencies in the data to ensure accuracy and reliability.\n",
    "- **Methods**:\n",
    "  - Use techniques like `dropna()` and `fillna()` in Pandas to manage missing values.\n",
    "  - Detect outliers through visualization or statistical methods (e.g., IQR).\n",
    "  \n",
    "#### 2. Data Transformation\n",
    "- **Definition**: Converting data from one format to another, changing data types, and scaling numerical values to bring them into a range.\n",
    "- **Methods**:\n",
    "  - Change data types using `.astype()`.\n",
    "  - Scale values using `MinMaxScaler` or `StandardScaler` from Scikit-learn.\n",
    "\n",
    "#### 3. Filtering and Sub-setting\n",
    "- **Definition**: Selecting specific rows or columns based on certain conditions to focus on relevant data for analysis.\n",
    "- **Methods**:\n",
    "  - Use boolean indexing (e.g., `df[df['column'] > value]`) to filter data.\n",
    "  - Subset columns by selecting a list of column names.\n",
    "\n",
    "#### 4. Data Aggregation\n",
    "- **Definition**: Combining data into groups and calculating summary statistics (e.g., mean, sum, count) for each group.\n",
    "- **Methods**:\n",
    "  - Use `.groupby()` followed by aggregation functions like `.sum()`, `.mean()`, or `.count()`.\n",
    "\n",
    "#### 5. Data Joining and Merging\n",
    "- **Definition**: Combining data from multiple sources based on common attributes to construct a unified dataset.\n",
    "- **Methods**:\n",
    "  - Use `pd.merge()` or `pd.concat()` to join DataFrames on keys.\n",
    "  - Specify join types (inner, outer, left, right) to control how data is combined.\n",
    "\n",
    "#### 6. Pivoting and Reshaping\n",
    "- **Definition**: Reorganizing data to change its structure, such as moving rows to columns or vice versa.\n",
    "- **Methods**:\n",
    "  - Use `pd.pivot_table()` to create pivot tables for summarizing data.\n",
    "  - Reshape data using `melt()` or `stack()`/`unstack()` functions.\n",
    "\n",
    "#### 7. Data Imputation\n",
    "- **Definition**: Filling in missing values using various techniques to maintain the integrity of the dataset.\n",
    "- **Methods**:\n",
    "  - Use statistical methods (mean, median, mode) or machine learning models for imputation.\n",
    "  - Consider KNN imputation or regression-based methods for more complex scenarios.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# STUDENT TASK DATA ANALYSIS (-> 12Uhr)\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "1. Data Cleaning and Preprocessing:\n",
    "   - Converted 'StartDate' to datetime\n",
    "   - Checked for missing values\n",
    "   - Handled outliers in the 'Salary' column using the IQR method\n",
    "\n",
    "2. Data Transformation:\n",
    "   - Created a new 'TenureYears' column\n",
    "   - Scaled 'Salary' and 'Bonuses' using pandas min-max scaling\n",
    "\n",
    "3. Filtering and Sub-setting:\n",
    "   - Created a subset of employees in the Development department\n",
    "   - Filtered employees with above-average performance\n",
    "\n",
    "4. Data Aggregation:\n",
    "   - Calculated average salary by department\n",
    "   - Computed performance rating statistics by role\n",
    "\n",
    "5. Data Joining and Merging:\n",
    "   - Created a separate DataFrame with department budget info\n",
    "   - Merged it with the main DataFrame\n",
    "\n",
    "6. Pivoting and Reshaping:\n",
    "   - Created a pivot table showing average performance rating for each role in each department\n",
    "\n",
    "7. Data Imputation:\n",
    "   - Introduced some missing values in 'TrainingHours' for demonstration\n",
    "   - Imputed missing values using the mean with pandas\n",
    "\n",
    "8. Data Visualization:\n",
    "   - Created a scatter plot of Years of Experience vs Salary\n",
    "   - Generated a bar plot of Average Performance Rating by Department\n",
    "   - Produced a heatmap of the correlation matrix\n",
    "\n",
    "9. Summary Statistics:\n",
    "   - Generated summary statistics for the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TenureYears calculation successful. Here's the result:\n",
      "  FirstName  LastName  StartDate  TenureYears\n",
      "0      John       Doe 2022-01-15     2.689552\n",
      "1      Jane     Smith 2021-06-01     3.313782\n",
      "2   Michael   Johnson 2023-03-10     1.542393\n",
      "3     Emily  Williams 2020-11-01     3.894206\n",
      "4     David     Brown 2022-07-15     2.194001\n",
      "5     Alice     Davis 2021-09-20     3.009881\n",
      "6    Robert    Wilson 2023-02-05     1.632742\n",
      "7     Laura     Moore 2022-10-25     1.914740\n",
      "8     James    Taylor 2020-12-01     3.812071\n",
      "Missing values:\n",
      "EmployeeID                 0\n",
      "FirstName                  0\n",
      "LastName                   0\n",
      "Role                       0\n",
      "Department                 0\n",
      "Salary                     0\n",
      "StartDate                  0\n",
      "Project                    0\n",
      "PerformanceRating          0\n",
      "Age                        0\n",
      "Education                  0\n",
      "YearsOfExperience          0\n",
      "Bonuses                    0\n",
      "WorkHoursPerWeek           0\n",
      "VacationDaysTaken          0\n",
      "TrainingHours              0\n",
      "TeamSize                   0\n",
      "ClientSatisfactionScore    0\n",
      "TenureYears                0\n",
      "dtype: int64\n",
      "\n",
      "Columns with 'NaN' strings:\n",
      "Project: 1 'NaN' strings\n",
      "\n",
      "Missing values after replacing 'NaN' strings:\n",
      "EmployeeID                 0\n",
      "FirstName                  0\n",
      "LastName                   0\n",
      "Role                       0\n",
      "Department                 0\n",
      "Salary                     0\n",
      "StartDate                  0\n",
      "Project                    1\n",
      "PerformanceRating          0\n",
      "Age                        0\n",
      "Education                  0\n",
      "YearsOfExperience          0\n",
      "Bonuses                    0\n",
      "WorkHoursPerWeek           0\n",
      "VacationDaysTaken          0\n",
      "TrainingHours              0\n",
      "TeamSize                   0\n",
      "ClientSatisfactionScore    0\n",
      "TenureYears                0\n",
      "dtype: int64\n",
      "\n",
      "Project column:\n",
      "0      Project Alpha\n",
      "1       Project Beta\n",
      "2      Project Gamma\n",
      "3      Project Delta\n",
      "4    Project Epsilon\n",
      "5       Project Zeta\n",
      "6      Project Alpha\n",
      "7       Project Beta\n",
      "8                NaN\n",
      "Name: Project, dtype: object\n",
      "\n",
      "Salary range after handling outliers:\n",
      "count        9.000000\n",
      "mean     71333.333333\n",
      "std       4092.676386\n",
      "min      65000.000000\n",
      "25%      69000.000000\n",
      "50%      71000.000000\n",
      "75%      73000.000000\n",
      "max      79000.000000\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "2. Data Transformation\n",
      "New columns added: TenureYears, Salary_Scaled, Bonuses_Scaled\n",
      "   TenureYears  Salary_Scaled  Bonuses_Scaled\n",
      "0     2.689552       0.357143        0.464286\n",
      "1     3.313782       0.714286        0.642857\n",
      "2     1.542393       0.214286        0.214286\n",
      "3     3.894206       1.000000        1.000000\n",
      "4     2.194001       0.000000        0.107143\n",
      "\n",
      "3. Filtering and Sub-setting\n",
      "Employees in Development department:\n",
      "  FirstName LastName                Role\n",
      "0      John      Doe   Software Engineer\n",
      "6    Robert   Wilson   Backend Developer\n",
      "7     Laura    Moore  Frontend Developer\n",
      "\n",
      "Employees with above-average performance:\n",
      "  FirstName  LastName  PerformanceRating\n",
      "0      John       Doe                4.5\n",
      "1      Jane     Smith                4.7\n",
      "3     Emily  Williams                4.6\n",
      "6    Robert    Wilson                4.4\n",
      "8     James    Taylor                4.8\n",
      "\n",
      "4. Data Aggregation\n",
      "Average salary by department:\n",
      "Department\n",
      "Management           79000.0\n",
      "Data Science         75000.0\n",
      "Human Resources      73000.0\n",
      "Operations           72000.0\n",
      "Development          70000.0\n",
      "Design               68000.0\n",
      "Quality Assurance    65000.0\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "Performance rating statistics by role:\n",
      "                    mean  min  max\n",
      "Role                              \n",
      "Backend Developer    4.4  4.4  4.4\n",
      "Data Scientist       4.7  4.7  4.7\n",
      "DevOps Engineer      4.3  4.3  4.3\n",
      "Frontend Developer   4.0  4.0  4.0\n",
      "HR Manager           4.8  4.8  4.8\n",
      "Product Manager      4.6  4.6  4.6\n",
      "QA Engineer          4.1  4.1  4.1\n",
      "Software Engineer    4.5  4.5  4.5\n",
      "UX Designer          4.2  4.2  4.2\n",
      "\n",
      "5. Data Joining and Merging\n",
      "Merged DataFrame with department budget:\n",
      "  FirstName  LastName         Department  Salary  Budget\n",
      "0      John       Doe        Development   70000  500000\n",
      "1      Jane     Smith       Data Science   75000  400000\n",
      "2   Michael   Johnson             Design   68000  300000\n",
      "3     Emily  Williams         Management   79000  450000\n",
      "4     David     Brown  Quality Assurance   65000  250000\n",
      "\n",
      "6. Pivoting and Reshaping\n",
      "Pivot table - Average performance rating by role and department:\n",
      "Role               Backend Developer  Data Scientist  DevOps Engineer  \\\n",
      "Department                                                              \n",
      "Data Science                     NaN             4.7              NaN   \n",
      "Design                           NaN             NaN              NaN   \n",
      "Development                      4.4             NaN              NaN   \n",
      "Human Resources                  NaN             NaN              NaN   \n",
      "Management                       NaN             NaN              NaN   \n",
      "Operations                       NaN             NaN              4.3   \n",
      "Quality Assurance                NaN             NaN              NaN   \n",
      "\n",
      "Role               Frontend Developer  HR Manager  Product Manager  \\\n",
      "Department                                                           \n",
      "Data Science                      NaN         NaN              NaN   \n",
      "Design                            NaN         NaN              NaN   \n",
      "Development                       4.0         NaN              NaN   \n",
      "Human Resources                   NaN         4.8              NaN   \n",
      "Management                        NaN         NaN              4.6   \n",
      "Operations                        NaN         NaN              NaN   \n",
      "Quality Assurance                 NaN         NaN              NaN   \n",
      "\n",
      "Role               QA Engineer  Software Engineer  UX Designer  \n",
      "Department                                                      \n",
      "Data Science               NaN                NaN          NaN  \n",
      "Design                     NaN                NaN          4.2  \n",
      "Development                NaN                4.5          NaN  \n",
      "Human Resources            NaN                NaN          NaN  \n",
      "Management                 NaN                NaN          NaN  \n",
      "Operations                 NaN                NaN          NaN  \n",
      "Quality Assurance          4.1                NaN          NaN  \n",
      "\n",
      "7. Data Imputation\n",
      "TrainingHours after imputation:\n",
      "0    30.0\n",
      "1    29.5\n",
      "2    29.5\n",
      "3    40.0\n",
      "4    20.0\n",
      "5    35.0\n",
      "6    29.5\n",
      "7    22.0\n",
      "8    30.0\n",
      "Name: TrainingHours, dtype: float64\n",
      "\n",
      "8. Data Visualization\n",
      "Visualizations saved as PNG files.\n",
      "\n",
      "9. Summary Statistics\n",
      "       EmployeeID        Salary            StartDate  PerformanceRating  \\\n",
      "count    9.000000      9.000000                    9           9.000000   \n",
      "mean     5.000000  71333.333333  2022-01-23 05:20:00           4.400000   \n",
      "min      1.000000  65000.000000  2020-11-01 00:00:00           4.000000   \n",
      "25%      3.000000  69000.000000  2021-06-01 00:00:00           4.200000   \n",
      "50%      5.000000  71000.000000  2022-01-15 00:00:00           4.400000   \n",
      "75%      7.000000  73000.000000  2022-10-25 00:00:00           4.600000   \n",
      "max      9.000000  79000.000000  2023-03-10 00:00:00           4.800000   \n",
      "std      2.738613   4092.676386                  NaN           0.273861   \n",
      "\n",
      "             Age  YearsOfExperience      Bonuses  WorkHoursPerWeek  \\\n",
      "count   9.000000           9.000000     9.000000          9.000000   \n",
      "mean   30.111111           5.888889  3411.111111         40.777778   \n",
      "min    25.000000           2.000000  2200.000000         38.000000   \n",
      "25%    27.000000           4.000000  2800.000000         40.000000   \n",
      "50%    29.000000           5.000000  3200.000000         40.000000   \n",
      "75%    32.000000           7.000000  4000.000000         42.000000   \n",
      "max    38.000000          12.000000  5000.000000         45.000000   \n",
      "std     4.314060           3.295620   931.993085          2.048034   \n",
      "\n",
      "       VacationDaysTaken  TrainingHours  TeamSize  ClientSatisfactionScore  \\\n",
      "count           9.000000       9.000000  9.000000                 9.000000   \n",
      "mean           10.222222      29.500000  5.444444                 4.233333   \n",
      "min             6.000000      20.000000  4.000000                 3.800000   \n",
      "25%             8.000000      29.500000  5.000000                 4.000000   \n",
      "50%            10.000000      29.500000  5.000000                 4.200000   \n",
      "75%            12.000000      30.000000  6.000000                 4.500000   \n",
      "max            15.000000      40.000000  8.000000                 4.700000   \n",
      "std             3.073181       5.994789  1.236033                 0.316228   \n",
      "\n",
      "       TenureYears  Salary_Scaled  Bonuses_Scaled  \n",
      "count     9.000000       9.000000        9.000000  \n",
      "mean      2.667041       0.452381        0.432540  \n",
      "min       1.542393       0.000000        0.000000  \n",
      "25%       1.914740       0.285714        0.214286  \n",
      "50%       2.689552       0.428571        0.357143  \n",
      "75%       3.313782       0.571429        0.642857  \n",
      "max       3.894206       1.000000        1.000000  \n",
      "std       0.899839       0.292334        0.332855  \n",
      "\n",
      "Analysis complete. Check the generated PNG files for visualizations.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Load the data\n",
    "data = {\n",
    "    'EmployeeID': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'FirstName': ['John', 'Jane', 'Michael', 'Emily', 'David', 'Alice', 'Robert', 'Laura', 'James'],\n",
    "    'LastName': ['Doe', 'Smith', 'Johnson', 'Williams', 'Brown', 'Davis', 'Wilson', 'Moore', 'Taylor'],\n",
    "    'Role': ['Software Engineer', 'Data Scientist', 'UX Designer', 'Product Manager', 'QA Engineer', 'DevOps Engineer', 'Backend Developer', 'Frontend Developer', 'HR Manager'],\n",
    "    'Department': ['Development', 'Data Science', 'Design', 'Management', 'Quality Assurance', 'Operations', 'Development', 'Development', 'Human Resources'],\n",
    "    'Salary': [70000, 75000, 68000, 80000, 65000, 72000, 71000, 69000, 73000],\n",
    "    'StartDate': ['2022-01-15', '2021-06-01', '2023-03-10', '2020-11-01', '2022-07-15', '2021-09-20', '2023-02-05', '2022-10-25', '2020-12-01'],\n",
    "    'Project': ['Project Alpha', 'Project Beta', 'Project Gamma', 'Project Delta', 'Project Epsilon', 'Project Zeta', 'Project Alpha', 'Project Beta', 'NaN'],\n",
    "    'PerformanceRating': [4.5, 4.7, 4.2, 4.6, 4.1, 4.3, 4.4, 4.0, 4.8],\n",
    "    'Age': [28, 32, 26, 35, 29, 31, 27, 25, 38],\n",
    "    'Education': [\"Bachelor's\", 'PhD', \"Master's\", 'MBA', \"Bachelor's\", \"Master's\", \"Bachelor's\", \"Bachelor's\", \"Master's\"],\n",
    "    'YearsOfExperience': [5, 7, 3, 10, 4, 6, 4, 2, 12],\n",
    "    'Bonuses': [3500, 4000, 2800, 5000, 2500, 3200, 3000, 2200, 4500],\n",
    "    'WorkHoursPerWeek': [40, 42, 38, 45, 40, 41, 40, 39, 42],\n",
    "    'VacationDaysTaken': [10, 15, 8, 12, 7, 11, 9, 6, 14],\n",
    "    'TrainingHours': [30, 45, 25, 40, 20, 35, 28, 22, 30],\n",
    "    'TeamSize': [6, 4, 5, 8, 6, 5, 6, 5, 4],\n",
    "    'ClientSatisfactionScore': [4.2, 4.5, 4.0, 4.7, 3.9, 4.3, 4.1, 3.8, 4.6]\n",
    "}\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'StartDate' to datetime\n",
    "df['StartDate'] = pd.to_datetime(df['StartDate'])\n",
    "\n",
    "# Calculate TenureYears\n",
    "df['TenureYears'] = (pd.Timestamp.now() - df['StartDate']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "\n",
    "print(\"TenureYears calculation successful. Here's the result:\")\n",
    "print(df[['FirstName', 'LastName', 'StartDate', 'TenureYears']])\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for 'NaN' strings\n",
    "print(\"\\nColumns with 'NaN' strings:\")\n",
    "for column in df.columns:\n",
    "    if df[column].astype(str).eq('NaN').any():\n",
    "        print(f\"{column}: {df[column].astype(str).eq('NaN').sum()} 'NaN' strings\")\n",
    "\n",
    "# Replace 'NaN' strings with actual NaN values\n",
    "df = df.replace('NaN', np.nan)\n",
    "\n",
    "# Check for missing values again\n",
    "print(\"\\nMissing values after replacing 'NaN' strings:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display the Project column\n",
    "print(\"\\nProject column:\")\n",
    "print(df['Project'])\n",
    "\n",
    "# Handle outliers in Salary using IQR method\n",
    "Q1 = df['Salary'].quantile(0.25)\n",
    "Q3 = df['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df['Salary'] = df['Salary'].clip(lower_bound, upper_bound)\n",
    "\n",
    "print(\"\\nSalary range after handling outliers:\")\n",
    "print(df['Salary'].describe())\n",
    "\n",
    "# 2. Data Transformation\n",
    "print(\"\\n2. Data Transformation\")\n",
    "\n",
    "# Create a new column 'TenureYears'\n",
    "df['TenureYears'] = (pd.Timestamp.now() - df['StartDate']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "\n",
    "# Scale Salary and Bonuses using pandas\n",
    "df['Salary_Scaled'] = (df['Salary'] - df['Salary'].min()) / (df['Salary'].max() - df['Salary'].min())\n",
    "df['Bonuses_Scaled'] = (df['Bonuses'] - df['Bonuses'].min()) / (df['Bonuses'].max() - df['Bonuses'].min())\n",
    "\n",
    "print(\"New columns added: TenureYears, Salary_Scaled, Bonuses_Scaled\")\n",
    "print(df[['TenureYears', 'Salary_Scaled', 'Bonuses_Scaled']].head())\n",
    "\n",
    "# 3. Filtering and Sub-setting\n",
    "print(\"\\n3. Filtering and Sub-setting\")\n",
    "\n",
    "# Subset of employees in Development department\n",
    "dev_employees = df[df['Department'] == 'Development']\n",
    "print(\"Employees in Development department:\")\n",
    "print(dev_employees[['FirstName', 'LastName', 'Role']])\n",
    "\n",
    "# Filter employees with above-average performance\n",
    "above_avg_performance = df[df['PerformanceRating'] > df['PerformanceRating'].mean()]\n",
    "print(\"\\nEmployees with above-average performance:\")\n",
    "print(above_avg_performance[['FirstName', 'LastName', 'PerformanceRating']])\n",
    "\n",
    "# 4. Data Aggregation\n",
    "print(\"\\n4. Data Aggregation\")\n",
    "\n",
    "# Average salary by department\n",
    "avg_salary_by_dept = df.groupby('Department')['Salary'].mean().sort_values(ascending=False)\n",
    "print(\"Average salary by department:\")\n",
    "print(avg_salary_by_dept)\n",
    "\n",
    "# Performance rating statistics by role\n",
    "perf_stats_by_role = df.groupby('Role')['PerformanceRating'].agg(['mean', 'min', 'max'])\n",
    "print(\"\\nPerformance rating statistics by role:\")\n",
    "print(perf_stats_by_role)\n",
    "\n",
    "# 5. Data Joining and Merging\n",
    "print(\"\\n5. Data Joining and Merging\")\n",
    "\n",
    "# Create a separate DataFrame with department budget info\n",
    "dept_budget = pd.DataFrame({\n",
    "    'Department': ['Development', 'Data Science', 'Design', 'Management', 'Quality Assurance', 'Operations', 'Human Resources'],\n",
    "    'Budget': [500000, 400000, 300000, 450000, 250000, 350000, 200000]\n",
    "})\n",
    "\n",
    "# Merge with the main DataFrame\n",
    "df_with_budget = pd.merge(df, dept_budget, on='Department', how='left')\n",
    "print(\"Merged DataFrame with department budget:\")\n",
    "print(df_with_budget[['FirstName', 'LastName', 'Department', 'Salary', 'Budget']].head())\n",
    "\n",
    "# 6. Pivoting and Reshaping\n",
    "print(\"\\n6. Pivoting and Reshaping\")\n",
    "\n",
    "# Pivot table: Average performance rating for each role in each department\n",
    "pivot_perf = pd.pivot_table(df, values='PerformanceRating', index='Department', columns='Role', aggfunc='mean')\n",
    "print(\"Pivot table - Average performance rating by role and department:\")\n",
    "print(pivot_perf)\n",
    "\n",
    "# 7. Data Imputation (for demonstration, let's assume some missing values in TrainingHours)\n",
    "print(\"\\n7. Data Imputation\")\n",
    "\n",
    "# Introduce some missing values in TrainingHours\n",
    "df.loc[df.sample(n=3).index, 'TrainingHours'] = None\n",
    "\n",
    "# Impute missing values with mean using pandas\n",
    "df['TrainingHours'] = df['TrainingHours'].fillna(df['TrainingHours'].mean())\n",
    "\n",
    "print(\"TrainingHours after imputation:\")\n",
    "print(df['TrainingHours'])\n",
    "\n",
    "# 8. Data Visualization\n",
    "print(\"\\n8. Data Visualization\")\n",
    "\n",
    "# Scatter plot: Years of Experience vs Salary\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='YearsOfExperience', y='Salary', hue='Department')\n",
    "plt.title('Years of Experience vs Salary')\n",
    "plt.savefig('experience_vs_salary.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar plot: Average Performance Rating by Department\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.groupby('Department')['PerformanceRating'].mean().sort_values().plot(kind='bar')\n",
    "plt.title('Average Performance Rating by Department')\n",
    "plt.tight_layout()\n",
    "plt.savefig('avg_performance_by_dept.png')\n",
    "plt.close()\n",
    "\n",
    "# Heatmap: Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df.select_dtypes(include=[int, float]).corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Visualizations saved as PNG files.\")\n",
    "\n",
    "# 9. Summary Statistics\n",
    "print(\"\\n9. Summary Statistics\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nAnalysis complete. Check the generated PNG files for visualizations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# TODAYS TASKS: YOUR OWN STARTUP ANALYSIS\n",
    "\n",
    "---\n",
    "\n",
    "USE YOUR OWN DATA, FIND ON THE INTERNET OR GENERATE WITH NUMPY OR A.I.\n",
    "\n",
    "FOLLOWING TASKS ARE JUST SAMPLES FOR A COMPANY HEALTH REPORT\n",
    "CREATE YOUR OWN IMPORTANT DECISIONS OR STATISTICS TO PRESENT\n",
    "\n",
    "### Task 1: Load and Inspect Data\n",
    "- **Objective**: Load the CSV files into Pandas DataFrames and inspect their structure.\n",
    "- **Action**: Use `pd.read_csv()` to load the datasets and `df.head()` to view the first few entries.\n",
    "\n",
    "### Task 2: Clean Data\n",
    "- **Objective**: Handle missing values and data types.\n",
    "- **Action**: Identify any missing data using `df.isnull().sum()`, and fill or drop missing values as necessary.\n",
    "\n",
    "### Task 3: Descriptive Statistics\n",
    "- **Objective**: Generate descriptive statistics for key numerical columns.\n",
    "- **Action**: Use `df.describe()` to summarize data.\n",
    "\n",
    "### Task 4: Visualize Revenue by Department\n",
    "- **Objective**: Create a bar chart to visualize total revenue by department.\n",
    "- **Action**: Use Matplotlib or Seaborn to plot the revenue data.\n",
    "\n",
    "### Task 5: Expense Breakdown by Department\n",
    "- **Objective**: Create a pie chart to show the breakdown of expenses by department.\n",
    "- **Action**: Use Matplotlib to create a pie chart from the expense data.\n",
    "\n",
    "### Task 6: Employee Performance Analysis\n",
    "- **Objective**: Visualize employee performance ratings using a box plot.\n",
    "- **Action**: Use Seaborn to create a box plot to display the distribution of performance ratings.\n",
    "\n",
    "### Task 7: Revenue vs. Expenses Scatter Plot\n",
    "- **Objective**: Create a scatter plot to visualize the relationship between revenue and expenses for each department.\n",
    "- **Action**: Use Seaborn's `scatterplot()` to visualize this relationship.\n",
    "\n",
    "### Task 8: Monthly Growth Rate by Department\n",
    "- **Objective**: Calculate and visualize the monthly growth rate of revenue by department.\n",
    "- **Action**: Compute growth rates and create a line chart for each department.\n",
    "\n",
    "### Task 9: Employee Distribution by Department\n",
    "- **Objective**: Create a count plot to visualize the distribution of employees across different departments.\n",
    "- **Action**: Use Seaborn’s `countplot()` to show the number of employees in each department.\n",
    "\n",
    "### Task 10: Dashboard Compilation\n",
    "- **Objective**: Compile all visualizations into a single dashboard layout.\n",
    "- **Action**: Use Matplotlib's subplots or other dashboarding libraries (like Dash) to create a cohesive dashboard view.\n",
    "\n",
    "\n",
    "THESE ARE SAMPLE TASKS IF YOU HAVE DATA CREATED OR GATHERED WITH DIFFERENT COLUMNS PLS FEEL FREE TO GENERATE YOUR OWN STATISTICS AND VISUALS TO MAKE A DECISION ABOUT THE COMPANY HEALTH AND POSSIBLE DECISION TO TAKE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---\n",
    "\n",
    "# INSTRUCTIONS \n",
    "\n",
    "---\n",
    "\n",
    "### Task 1: Load and Inspect Data\n",
    "1. **Load Data**:\n",
    "   - Use `pd.read_csv()` to load `financial_data.csv` and `employee_data.csv` into separate DataFrames (e.g., `financial_df` and `employee_df`).\n",
    "2. **Inspect Data**:\n",
    "   - Use the `.head()` method on both DataFrames to display the first five rows.\n",
    "   - Check the structure (columns and data types) using `.info()`.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 2: Clean Data\n",
    "1. **Check for Missing Values**:\n",
    "   - Use `df.isnull().sum()` on both DataFrames to identify any columns with missing values.\n",
    "2. **Handle Missing Values**:\n",
    "   - Decide on a strategy for each column:\n",
    "     - Fill missing values with a default (e.g., mean, median, or mode).\n",
    "     - Drop rows with missing values if appropriate.\n",
    "   - Implement the chosen method using `.fillna()` or `.dropna()`.\n",
    "\n",
    "3. **Data Types**:\n",
    "   - Ensure that each column has the correct data type (e.g., dates as datetime, categorical data as category).\n",
    "   - Convert data types as needed using `.astype()`.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 3: Descriptive Statistics\n",
    "1. **Generate Statistics**:\n",
    "   - Use `.describe()` on both DataFrames to summarize key numerical columns (e.g., Revenue, Expenses, PerformanceRating).\n",
    "   - Pay attention to count, mean, standard deviation, min, max, and quartiles.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 4: Visualize Revenue by Department\n",
    "1. **Group Data**:\n",
    "   - Group `financial_df` by `Department` and sum the `Revenue`.\n",
    "2. **Create Bar Chart**:\n",
    "   - Use Matplotlib or Seaborn to create a bar chart that displays total revenue for each department.\n",
    "   - Add titles, labels, and customize colors for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 5: Expense Breakdown by Department\n",
    "1. **Group Data**:\n",
    "   - Group `financial_df` by `Department` and sum the `Expenses`.\n",
    "2. **Create Pie Chart**:\n",
    "   - Use Matplotlib to create a pie chart showing the percentage breakdown of expenses by department.\n",
    "   - Add a title and consider adding percentage labels to the slices.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 6: Employee Performance Analysis\n",
    "1. **Create Box Plot**:\n",
    "   - Use Seaborn to create a box plot for the `PerformanceRating` grouped by `Department`.\n",
    "   - Add appropriate titles and customize axes for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 7: Revenue vs. Expenses Scatter Plot\n",
    "1. **Create Scatter Plot**:\n",
    "   - Use Seaborn's `scatterplot()` to visualize the relationship between `Revenue` and `Expenses`.\n",
    "   - Color points by `Department` to distinguish them easily.\n",
    "   - Add titles and axis labels.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 8: Monthly Growth Rate by Department\n",
    "1. **Calculate Growth Rates**:\n",
    "   - Compute the growth rate of revenue month-over-month for each department.\n",
    "   - Consider using the formula: `growth_rate = (current_month_revenue - previous_month_revenue) / previous_month_revenue`.\n",
    "2. **Create Line Chart**:\n",
    "   - Use Matplotlib to create a line chart for each department showing the monthly growth rate.\n",
    "   - Use different colors or styles for each department and include a legend.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 9: Employee Distribution by Department\n",
    "1. **Create Count Plot**:\n",
    "   - Use Seaborn’s `countplot()` to visualize the number of employees in each department.\n",
    "   - Customize the plot with titles and adjust the x-axis labels for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "### Task 10: Dashboard Compilation\n",
    "1. **Compile Visualizations**:\n",
    "   - Use Matplotlib’s `subplots()` to create a grid layout for all visualizations.\n",
    "   - Arrange each plot logically (e.g., revenue, expenses, performance) in the dashboard.\n",
    "2. **Customize Layout**:\n",
    "   - Adjust the size of the figure, add overall titles, and ensure proper spacing between plots for a clean appearance.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
