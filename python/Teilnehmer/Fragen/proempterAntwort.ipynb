{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"kindle_data.csv\")\n",
    "\n",
    "#Trim whitespaces frim column names -> durch die Erweiterung Rainbow sind whitespaces enstanden, die raus müssen\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns\n",
    "\n",
    "df.head()\n",
    "\n",
    "#remove column\n",
    "\n",
    "df_new = df.drop([\"imgUrl\", \"productURL\"], axis=1)\n",
    "df_new.head()\n",
    "\n",
    "#in Dataframe df = Replace im Dataframe df die NaN -> er würde sonst das NaN nicht erkennen\n",
    "df_new = df_new.replace(\"NaN\", np.nan)\n",
    "\n",
    "#check for None/NaN\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Reihen mit NaN entfernen\n",
    "df_new.dropna(inplace=True)\n",
    "\n",
    "df_new.head()\n",
    "\n",
    "#Dataset auf doppelte Titel testen\n",
    "title_counts = df_new[\"title\"].value_counts()\n",
    "num_duplicates = len(title_counts[title_counts > 1])\n",
    "\n",
    "print(title_counts)\n",
    "\n",
    "print(f\"\\nEs sind {num_duplicates} doppelte Titel enthalten\")\n",
    "\n",
    "#Duplikate filtern\n",
    "\n",
    "df_new_unique = df_new.drop_duplicates(subset=[\"title\"])\n",
    "\n",
    "df_new_unique.head()\n",
    "\n",
    "df_new_unique = df_new_unique[df_new_unique['reviews'] >= 648]\n",
    "\n",
    "#df_new_unique['reviews'].describe()\n",
    "\n",
    "df_new_unique.sort_values(\"reviews\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "# Select top N authors with the most bestsellers\n",
    "top_authors = df_new_unique['author'].value_counts().head(20).index\n",
    "sns.countplot(data=df_new_unique[df_new_unique['author'].isin(top_authors)], y=\"author\", order=top_authors)\n",
    "\n",
    "plt.title(\"Top 20 Authors by Number of Bestsellers\")\n",
    "plt.ylabel(\"Author\")\n",
    "plt.xlabel(\"Number of Bestsellers\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Get the count of bestsellers by author\n",
    "author_counts = df_new_unique['author'].value_counts().reset_index()\n",
    "author_counts.columns = ['Author', 'Number of Bestsellers']\n",
    "\n",
    "# Create the plotly figure\n",
    "fig = px.bar(author_counts.head(100),  # Display the top 50 authors for example\n",
    "             y='Author', \n",
    "             x='Number of Bestsellers', \n",
    "             orientation='h',\n",
    "             title='Top Authors by Number of Bestsellers')\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis={'categoryorder':'total ascending'},\n",
    "    height=800,  # Adjust the height to make it more readable and scrollable\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Create the count data from your DataFrame\n",
    "author_counts = df_new_unique['author'].value_counts().reset_index()\n",
    "author_counts.columns = ['Author', 'Number of Bestsellers']\n",
    "\n",
    "# Set page size and initialize start index\n",
    "page_size = 100\n",
    "start_index = 0\n",
    "\n",
    "def plot_page(start_index=0, page_size=100):\n",
    "    # Get the subset of data for the current page\n",
    "    author_subset = author_counts.iloc[start_index:start_index + page_size]\n",
    "    \n",
    "    fig = px.bar(author_subset,\n",
    "                 y='Author',\n",
    "                 x='Number of Bestsellers',\n",
    "                 orientation='h',\n",
    "                 title=f'Top Authors by Number of Bestsellers (Showing {start_index + 1} to {min(start_index + page_size, len(author_counts))})')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        yaxis={'categoryorder': 'total ascending', 'autorange': 'reversed'},\n",
    "        height=800  # Adjust height based on the number of items per page\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Function to handle pagination\n",
    "def paginate(action):\n",
    "    global start_index\n",
    "    if action == 'next' and start_index + page_size < len(author_counts):\n",
    "        start_index += page_size\n",
    "    elif action == 'prev' and start_index - page_size >= 0:\n",
    "        start_index -= page_size\n",
    "    else:\n",
    "        print(\"No more pages in this direction.\")\n",
    "    \n",
    "    plot_page(start_index, page_size)\n",
    "\n",
    "# Display the first page\n",
    "plot_page(start_index=start_index, page_size=page_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will plot the next 100\n",
    "paginate('next')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Pagination**\n",
    "   - **Concept**: Display data in smaller chunks (pages) rather than all at once. Users can navigate through these pages.\n",
    "   - **Implementation**: The example I provided above shows how to implement pagination using Plotly in Python.\n",
    "   - **Pros**: Allows users to interact with large datasets without overwhelming the viewer or system resources.\n",
    "   - **Cons**: Not suitable for an overview; it's more for detailed, segmented analysis.\n",
    "\n",
    "### 2. **Zooming and Panning**\n",
    "   - **Concept**: Allow users to zoom into specific areas of the graph and pan across the data. Most modern libraries, like Plotly and Bokeh, support interactive zooming and panning out of the box.\n",
    "   - **Implementation**: Simply enabling the interactive mode in Plotly, matplotlib (`%matplotlib notebook` in Jupyter), or using `plotly.express` with large data allows for zooming.\n",
    "   - **Pros**: Gives the ability to explore detailed sections without losing context of the whole dataset.\n",
    "   - **Cons**: May still be slow to render initially if the dataset is extremely large.\n",
    "\n",
    "### 3. **Filtering**\n",
    "   - **Concept**: Allow users to filter data based on certain criteria before displaying it. For example, you might want to display only authors with more than a certain number of bestsellers.\n",
    "   - **Implementation**: Add dropdowns or sliders to filter data dynamically. This can be done with libraries like Plotly’s interactive widgets, Dash, or Streamlit.\n",
    "   - **Pros**: Helps in focusing on relevant data and reduces clutter.\n",
    "   - **Cons**: Requires some interactive control, so it might not be as suitable for static presentations.\n",
    "\n",
    "### 4. **Aggregation and Binning**\n",
    "   - **Concept**: Aggregate or bin data into summarized categories. For example, group authors by letter or count them into ranges.\n",
    "   - **Implementation**: Use pandas’ `groupby` function to aggregate data before plotting or use histograms and heatmaps to display aggregated data.\n",
    "   - **Pros**: Reduces data size while preserving key trends and patterns.\n",
    "   - **Cons**: You lose granular detail, and it might not be suitable for situations requiring precise information.\n",
    "\n",
    "### 5. **Sampling**\n",
    "   - **Concept**: Select a representative subset of data points instead of plotting the entire dataset.\n",
    "   - **Implementation**: Use pandas’ `.sample()` method to extract a random sample of your data.\n",
    "   - **Pros**: Reduces rendering time and complexity while still representing the general pattern.\n",
    "   - **Cons**: Important outliers might be missed if not carefully sampled.\n",
    "\n",
    "### 6. **Chunk Processing**\n",
    "   - **Concept**: Process and visualize the data in chunks. You only load and visualize a manageable portion of the data at a time.\n",
    "   - **Implementation**: Load data from disk in smaller chunks using libraries like Dask or by processing data in SQL queries with `LIMIT`.\n",
    "   - **Pros**: Handles very large datasets that don’t fit into memory.\n",
    "   - **Cons**: Increases complexity in handling data and might miss overall trends if not implemented carefully.\n",
    "\n",
    "### 7. **Hierarchical Visualization (Drill-down Approach)**\n",
    "   - **Concept**: Start with a high-level aggregated view (e.g., country-level data) and then allow users to drill down to more detailed levels (e.g., city, street).\n",
    "   - **Implementation**: Tools like Plotly, Tableau, or PowerBI support hierarchical visualization natively.\n",
    "   - **Pros**: Provides a multi-layered approach to explore data at different granularities.\n",
    "   - **Cons**: Requires some setup and configuration; less effective in purely static environments.\n",
    "\n",
    "### 8. **Using Interactive Visualization Libraries**\n",
    "   - **Concept**: Use advanced visualization libraries that handle big data more efficiently with interactivity, such as:\n",
    "     - **Plotly**: Great for interactive, zoomable, and filterable plots.\n",
    "     - **Bokeh**: Supports interactive visualization with more control over details.\n",
    "     - **Dash**: Build interactive web applications with custom filtering.\n",
    "     - **Datashader**: Specifically designed for rendering large datasets quickly, capable of visualizing millions of points.\n",
    "   - **Pros**: Rich interactivity and flexibility.\n",
    "   - **Cons**: Requires familiarity with the library and sometimes more complex code.\n",
    "\n",
    "### 9. **Heatmaps or Density Plots**\n",
    "   - **Concept**: Use heatmaps or density plots to visualize large amounts of data points, where color intensity represents data density.\n",
    "   - **Implementation**: Use `sns.heatmap()` in Seaborn or `px.density_heatmap()` in Plotly.\n",
    "   - **Pros**: Effective for showing patterns and trends in large datasets.\n",
    "   - **Cons**: Aggregates data into bins, so you lose individual data point precision.\n",
    "\n",
    "### 10. **Scatter Plot with Alpha Blending**\n",
    "   - **Concept**: Reduce the opacity (alpha) of points in a scatter plot so overlapping areas appear darker, allowing you to spot high-density regions.\n",
    "   - **Implementation**: Set `alpha` parameter in matplotlib/Seaborn or `opacity` in Plotly.\n",
    "   - **Pros**: Shows density of data points while still allowing all data to be plotted.\n",
    "   - **Cons**: Can become hard to read if the dataset is extremely dense.\n",
    "\n",
    "### 11. **Lazy Loading**\n",
    "   - **Concept**: Load data incrementally as the user interacts with the visualization. Data is fetched and rendered only as needed.\n",
    "   - **Implementation**: Create a web-based dashboard with libraries like Dash or Streamlit, which support data fetching in parts.\n",
    "   - **Pros**: Efficiently manages large datasets without overwhelming memory or CPU resources.\n",
    "   - **Cons**: Requires interactive frameworks and can be more complex to implement.\n",
    "\n",
    "### 12. **Cluster Sampling and Visualization**\n",
    "   - **Concept**: Use clustering algorithms (e.g., KMeans) to group similar data points and visualize these clusters instead of individual points.\n",
    "   - **Implementation**: Use scikit-learn for clustering, then visualize with your preferred library.\n",
    "   - **Pros**: Reduces the dataset to manageable clusters while showing overall trends.\n",
    "   - **Cons**: Requires additional data preprocessing.\n",
    "\n",
    "### 13. **Parallel Processing for Rendering**\n",
    "   - **Concept**: Use parallel processing to split the workload of plotting across multiple CPU cores.\n",
    "   - **Implementation**: Utilize libraries like Dask or `multiprocessing` to process data in parallel.\n",
    "   - **Pros**: Handles very large datasets more efficiently.\n",
    "   - **Cons**: Increased complexity and requires multi-core support.\n",
    "\n",
    "### 14. **Streaming Visualization**\n",
    "   - **Concept**: Stream data incrementally into your visualization so that it updates in real-time as new data arrives.\n",
    "   - **Implementation**: Use frameworks like Dash, Bokeh with streaming support, or Plotly’s `extendData`.\n",
    "   - **Pros**: Ideal for real-time data visualization.\n",
    "   - **Cons**: Requires an environment that supports real-time data feeds.\n",
    "\n",
    "### 15. **Data Reduction Techniques**\n",
    "   - **Concept**: Use data reduction methods like Principal Component Analysis (PCA) to reduce the dimensionality or complexity of the data.\n",
    "   - **Implementation**: Use scikit-learn’s PCA or t-SNE for dimensionality reduction, then visualize.\n",
    "   - **Pros**: Retains key information while reducing data size.\n",
    "   - **Cons**: Can be complex to interpret reduced dimensions.\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Technique                  | Suitable For                   | Pros                                   | Cons                                   |\n",
    "|----------------------------|--------------------------------|---------------------------------------|---------------------------------------|\n",
    "| Pagination                 | Very large datasets            | Easy to navigate small chunks         | Not suitable for overall trends       |\n",
    "| Zooming & Panning          | All data sizes                 | Interactive and detailed              | Requires user interaction             |\n",
    "| Filtering                  | Data with many dimensions      | Focus on specific data                | Interaction required                  |\n",
    "| Aggregation/Binning        | High-volume data points        | Simplifies data, shows trends         | Loss of detail                        |\n",
    "| Sampling                   | Extremely large datasets       | Reduces rendering time                | May miss important points             |\n",
    "| Chunk Processing           | Out-of-memory datasets         | Handles large data                    | Increased complexity                  |\n",
    "| Hierarchical Visualization | Multi-level data               | Different granular views              | Configuration required                |\n",
    "| Interactive Libraries      | Real-time & large datasets     | High interactivity                    | Learning curve                        |\n",
    "| Heatmaps/Density Plots     | Large datasets                 | Shows density patterns                | Loss of point-level detail            |\n",
    "| Alpha Blending             | Overlapping data               | Reveals density naturally             | Can be unclear in dense regions       |\n",
    "| Lazy Loading               | Large datasets                 | Efficient data handling               | Requires interactive setup            |\n",
    "| Clustering                 | Data with natural groups       | Shows trends with reduced data        | Needs preprocessing                   |\n",
    "| Parallel Processing        | Extremely large data           | Faster processing                     | More complex setup                    |\n",
    "| Streaming Visualization    | Real-time data                 | Up-to-date insights                   | Complex to implement                  |\n",
    "| Data Reduction             | High-dimensional data          | Simplifies data visualization         | Can lose interpretability             |\n",
    "\n",
    "### Choosing the Right Approach\n",
    "- For **overview** insights: Aggregation, binning, and density plots work best.\n",
    "- For **detailed analysis**: Zooming/panning, pagination, and filtering are ideal.\n",
    "- For **interactive dashboards**: Use libraries like Plotly, Dash, or Bokeh combined with filtering and lazy loading.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
